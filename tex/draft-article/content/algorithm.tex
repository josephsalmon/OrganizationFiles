%!TEX root = ../article.tex


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithms}
\label{sec:algorithms}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Considering the techniques mentioned by \citet{Jaggi13}, you can use a different algorithm a in say \Cref{alg:DC}



{\fontsize{4}{4}\selectfont
\begin{algorithm}[h]  % again h stands for here
\SetKwInOut{Input}{input}
\SetKwInOut{Init}{init}
\SetKwInOut{Parameter}{param}
\caption{\textsc{Implicit differentiation}
}
%
\Input{$
    X \in \bbR^{n \times p},
    y \in \bbR^{n},
    \lambda \in \bbR,
    n_{\text{iter}} \in \bbN$}
    \tcp{jointly compute coef. and Jacobian}

    \If{Lasso}{
    Get $\beta = Lasso(X, y, \lambda, n_{\text{iter}})
    $ and its support $\hat S$.

    $\hat J_{\phantom{\hat S}} = 0_{p}$ 
    \tcp{affectation}

    $\hat J_{\hat S} =
    - n e^\lambda (X_{\hat S}^\top X_{\hat S})^{-1} \sign \beta_{\hat S} $
    }
    \If{wLasso}{
    Get $\beta = wLasso(X, y, \lambda, n_{\text{iter}})
    $ and its support $\hat S$.

    $\hat J = 0_{p \times p}$

    $\hat J_{\hat S, \hat S} =
    - (X_{\hat S}^\top X_{\hat S})^{-1}
    \diag ( n e^{\lambda_{\hat S}}
    \odot \sign \beta_{\hat S})$
    }
\For{$k = 0,\dots, n_{\text{iter\_jac}} - 1$
    }{a = 1}

\Return{$\beta, \hat J$}
\label{alg:compute_jac_implicit_diff}
\end{algorithm}
}


It is also possible to use the standard citation style \cite{Tibshirani96}.
